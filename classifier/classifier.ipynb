{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.transforms import functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\r\n",
    "            nn.BatchNorm2d(32),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\r\n",
    "            nn.BatchNorm2d(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\r\n",
    "            nn.BatchNorm2d(128),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\r\n",
    "        )\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Linear(10368, 625), # 4 * 4 * 128\r\n",
    "            nn.BatchNorm1d(625),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(625, 22)\r\n",
    "        )        \r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = out.view(out.size(0), -1)\r\n",
    "        return self.layer2(out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = ConvNet()\r\n",
    "model.load_state_dict(torch.load('./state_dicts/classifier.w'))\r\n",
    "model.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pic_width = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eye_labels = [\r\n",
    "    'aqua',\r\n",
    "    'black',\r\n",
    "    'blue',\r\n",
    "    'brown',\r\n",
    "    'green',\r\n",
    "    'orange',\r\n",
    "    'pink',\r\n",
    "    'purple',\r\n",
    "    'red',\r\n",
    "    'yellow'\r\n",
    "]\r\n",
    "\r\n",
    "hair_labels = [\r\n",
    "    'aqua',\r\n",
    "    'black',\r\n",
    "    'blonde',\r\n",
    "    'blue',\r\n",
    "    'brown',\r\n",
    "    'gray',\r\n",
    "    'green',\r\n",
    "    'orange',\r\n",
    "    'pink',\r\n",
    "    'purple',\r\n",
    "    'red',\r\n",
    "    'white'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def color_transform(x):\r\n",
    "    x = F.adjust_saturation(x, 2.5)\r\n",
    "    x = F.adjust_gamma(x, 0.7)\r\n",
    "    x = F.adjust_contrast(x, 1.2)\r\n",
    "    return x\r\n",
    "\r\n",
    "transform = transforms.Compose([\r\n",
    "        transforms.Resize((pic_width, pic_width)),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = Image.open('Chiaki2.png')\r\n",
    "img = color_transform(img)\r\n",
    "dimg = transform(img)\r\n",
    "\r\n",
    "batch = []\r\n",
    "\r\n",
    "for i in range(32):\r\n",
    "    batch.append(dimg)\r\n",
    "\r\n",
    "batch = tuple(batch)\r\n",
    "\r\n",
    "X = torch.stack(batch)\r\n",
    "\r\n",
    "Y_pred = model(X.to(device))\r\n",
    "Y_pred_eye = Y_pred[:, :10]\r\n",
    "Y_pred_hair = Y_pred[:, 10:]\r\n",
    "    \r\n",
    "Y_pred_eye_idx = Y_pred_eye.argmax(dim=1)\r\n",
    "Y_pred_hair_idx = Y_pred_hair.argmax(dim=1)\r\n",
    "\r\n",
    "plt.figure(figsize=(5, 5))\r\n",
    "plt.imshow(X.cpu()[0].permute(1, 2, 0))\r\n",
    "pred_eye_col = eye_labels[Y_pred_eye_idx.cpu()[0]]\r\n",
    "pred_hair_col = hair_labels[Y_pred_hair_idx.cpu()[0]]\r\n",
    "plt.title(f'I think the eyes are {pred_eye_col} and the hair is {pred_hair_col}')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}